
CLASSES = ['0', '2', '4']

def load_tweet_data(input_file_name, max_per_class):
    """ Return a list of tweets (at most max_per_class of each class) 
        If max_per_class is -1, return all tweets for each class.
        Tweets are just the tokenized strings from the file generated by 
        twtt.py.
    """ 
    pass


def num_sentences(tweet):
    """ Return the number of sentences in tweet."""
    pass


def avg_token_length(tweet):
    """ Return the average length of tokens in tweet
        measured by number of characters.
    """
    pass

    
def avg_sentence_length(tweet):
    """ Return the average length of sentences in tweet,
        measured by number of tokens 
    """
    pass
    

def tag_counts(tweet):
    """ Return a dictionary of token tags to number of occurences 
        in tweet.
    """
    pass


def count_pronouns(tweet):
    """ Count occurences of first, second, and third 
        person pronouns
    """
    pass


def count_conjunctions(tweet):
    """ Count occurences of the following: 
        and, but, for, nor, or, so, yet
    """
    pass


def count_verbs(tweet):
    """Count occurences of past and future tense verbs"""
    pass


def count_nouns(tweet):
    pass


def count_adverbs(tweet):
    pass


def count_wh_words(tweet):
    pass


def count_slang(tweet):
    pass


def count_uppercase(tweet): 
    """ Count occurences of uppercase words. 
        Exclude single character words.
    """
    pass


def count_punctuation(tweet):
    """ Count occurences of: 
        , : ; - ( ) ...
    """
    pass




if __name__ == "__main__":
    args = sys.argv
    input_file_name = args[1] # eg train.twt
    output_file_name = args[2]  # eg train.arff
    if len(args) == 4:
        max_per_class = int(args[3])
    else:
        max_per_class = -1

    tweets = load_tweet_data(input_file_name, max_per_class)
    
